{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn.linear_model as skl\n",
    "\n",
    "\n",
    "\n",
    "class RegressionMethods:\n",
    "    \"\"\"\n",
    "    Class implementation of the OLS, Ridge and Lasso regression methods.\n",
    "    Initiate with a specification of which method to use, and hyperparameter alpha for Ridge and Lasso.\n",
    "    The OLS and Ridge methods find the analytical beta-parameters, the Lasso method is a call to\n",
    "    sklearns Lasso method.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, method = 'ols', alpha = 0):\n",
    "        self.method = method\n",
    "        self.alpha = alpha\n",
    "\n",
    "\n",
    "    def ols(self):\n",
    "        \"\"\"\n",
    "        Finds the beta-parameters by OLS regression.\n",
    "        In case of singular matrix, uses the pseudo inverse in\n",
    "        calculation of beta.\n",
    "        \"\"\"\n",
    "        XT = self.X.T\n",
    "        self.beta = np.linalg.pinv(XT.dot(self.X)).dot(XT).dot(self.z)\n",
    "\n",
    "\n",
    "    def ridge(self):\n",
    "        \"\"\"\n",
    "        Finds the beta-parameters by Ridge regression.\n",
    "        In case of singular matrix, uses the pseudo inverse in\n",
    "        calculation of beta.\n",
    "        \"\"\"\n",
    "        XT = self.X.T\n",
    "        p = np.shape(self.X)[1]\n",
    "        L = np.identity(p)*self.alpha\n",
    "        self.beta = np.linalg.pinv(XT.dot(self.X) + L).dot(XT).dot(self.z)\n",
    "\n",
    "\n",
    "    def lasso(self):\n",
    "        clf = skl.Lasso(alpha = self.alpha, fit_intercept=False, normalize=False, max_iter=10000, tol=0.006).fit(self.X, self.z)\n",
    "        self.beta = clf.coef_\n",
    "\n",
    "\n",
    "    def fit(self, X, z):\n",
    "        \"\"\"\n",
    "        Fits the specified model to the data. Makes a call to the\n",
    "        relevant regression method.\n",
    "        Inputs:\n",
    "        -Design matrix X, dimension (n, p)\n",
    "        -Target values z, dimension (n, 1)\n",
    "        \"\"\"\n",
    "        self.X = X\n",
    "        self.z = z\n",
    "        if self.method == 'ols':\n",
    "            self.ols()\n",
    "        elif self.method == 'ridge':\n",
    "            self.ridge()\n",
    "        elif self.method == 'lasso':\n",
    "            self.lasso()\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Does a prediction on a set of data with the\n",
    "        parameters beta found by the fit-method.\n",
    "        Input:\n",
    "        -Data to be predicted on, in a matrix (n, p)\n",
    "        \"\"\"\n",
    "        self.z_tilde = X @ self.beta\n",
    "        return self.z_tilde\n",
    "\n",
    "\n",
    "    def set_alpha(self, alpha):\n",
    "        \"\"\"\n",
    "        Change the alpha parameter after initialiation.\n",
    "        \"\"\"\n",
    "        self.alpha = alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "\n",
    "class Resampling:\n",
    "    \"\"\"\n",
    "    Class for performing a train/test split and bootstrap resampling.\n",
    "    Is initialized with the whole data set, splitting in training and testing\n",
    "    data is performed by the methods.\n",
    "    \"\"\"\n",
    "    def __init__(self, X, z):\n",
    "        self.X = X.astype('float64')\n",
    "        self.z = z.astype('float64')\n",
    "\n",
    "\n",
    "    def train_test(self, model, test_size = 0.2):\n",
    "        \"\"\"\n",
    "        Performs a simple train/test split and trains a model on the train data\n",
    "        and returns the errors of the predictions on the test data.\n",
    "        Inputs:\n",
    "        -model, instanciated model\n",
    "        -test_size, how much of the data to be used in testing\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        #split the data in training and test\n",
    "        X_train, X_test, z_train, z_test = train_test_split(self.X, self.z, test_size = test_size)\n",
    "\n",
    "        #fit the model on the train data\n",
    "        model.fit(X_train, z_train)\n",
    "\n",
    "        #predict on the test data\n",
    "        z_pred = model.predict(X_test)\n",
    "\n",
    "        #calculate errors\n",
    "        error = np.mean((z_test - z_pred)**2)\n",
    "        bias = np.mean((z_test - np.mean(z_pred))**2)\n",
    "        variance = np.var(z_pred)\n",
    "        r2 = r2_score(z_test, z_pred)\n",
    "\n",
    "        return error, bias, variance, r2\n",
    "\n",
    "\n",
    "    def bootstrap(self, model, n_bootstraps = 100, test_size = 0.2, get_beta_var = False):\n",
    "        \"\"\"\n",
    "        Performs bootstrap resampling and returns the error scores of both training and\n",
    "        test data. Can also return the beta-parameters with its variance if specified.\n",
    "        Inputs:\n",
    "        -model, instanciated model\n",
    "        -n_bootstraps, how many bootstrap resamplings to perform\n",
    "        -test_size, how much of the data to be used in testing\n",
    "        -get_beta_var, whether to return only beta values and their variance\n",
    "        \"\"\"\n",
    "\n",
    "        #split data in training and testing\n",
    "        X_train, X_test, z_train, z_test = train_test_split(self.X, self.z, test_size = test_size)\n",
    "        sampleSize = X_train.shape[0]\n",
    "        n_betas = np.shape(self.X)[1]\n",
    "\n",
    "        #setup arrays for storing prediction values\n",
    "        z_pred = np.empty((z_test.shape[0], n_bootstraps))\n",
    "        z_train_pred = np.empty((z_train.shape[0], n_bootstraps))\n",
    "        z_train_boot = np.empty((z_train.shape[0], n_bootstraps))\n",
    "        betas = np.empty((n_betas, n_bootstraps))\n",
    "        r2 = np.empty(n_bootstraps)\n",
    "\n",
    "\n",
    "        #perform the resamplings\n",
    "        for i in range(n_bootstraps):\n",
    "\n",
    "            #pick random values in the training data and fit the model to it\n",
    "            indices = np.random.randint(0, sampleSize, sampleSize)\n",
    "            X_, z_ = X_train[indices], z_train[indices]\n",
    "            model.fit(X_, z_)\n",
    "\n",
    "            #save z-values of the training set\n",
    "            z_train_boot[:,i] = z_\n",
    "\n",
    "            #predict on the same test data each time\n",
    "            z_pred[:,i] = model.predict(X_test)\n",
    "            z_train_pred[:,i] = model.predict(X_)\n",
    "            betas[:,i] = model.beta\n",
    "            r2[i] = r2_score(z_pred[:,i], z_test)\n",
    "\n",
    "\n",
    "        z_test = z_test.reshape((len(z_test), 1))\n",
    "\n",
    "        #calculate mean error scores\n",
    "        error = np.mean( np.mean((z_pred - z_test)**2, axis=1, keepdims=True))\n",
    "        error_train = np.mean( np.mean((z_train_pred - z_train_boot)**2, axis=1, keepdims=True))\n",
    "        bias = np.mean( (z_test - np.mean(z_pred, axis=1, keepdims=True))**2 )\n",
    "        variance = np.mean( np.var(z_pred, axis=1, keepdims=True) )\n",
    "\n",
    "\n",
    "        beta_variance = np.var(betas, axis=1)\n",
    "        betas = np.mean(betas, axis=1)\n",
    "\n",
    "\n",
    "        if get_beta_var:\n",
    "            return betas, beta_variance\n",
    "        else:\n",
    "            return error, bias, variance, error_train, np.mean(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib as mpl\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "from imageio import imread\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def load_terrain(filename):\n",
    "    \"\"\"\n",
    "    Function to load terrain data and convert it to a 2D array\n",
    "    Returns a rescaled version of the array and its dimensions.\n",
    "    \"\"\"\n",
    "    slice = 2\n",
    "    terrain = imread('data/' + filename)\n",
    "    dims = np.shape(terrain)\n",
    "    print(dims)\n",
    "    if dims[0] != dims[1]:\n",
    "        terrain = terrain[0:dims[1], :]\n",
    "        dims = terrain.shape\n",
    "    terrain = terrain[0:dims[0]//2, 0:dims[1]//2]\n",
    "    terrain = terrain[0:-1:slice, 0:-1:slice]\n",
    "    dims = np.shape(terrain)\n",
    "    print(filename, 'loaded.', dims[0],'x',dims[1])\n",
    "    return terrain*0.001, dims[0]\n",
    "\n",
    "\n",
    "def show_terrain(terrain_data):\n",
    "    \"\"\"\n",
    "    Simple function for showing the raw terrain data\n",
    "    \"\"\"\n",
    "    terrain1 = imread(terrain_data)\n",
    "    plt.figure()\n",
    "    plt.title('Terrain')\n",
    "    plt.imshow(terrain1, cmap='gray')\n",
    "    plt.xlabel('X')\n",
    "    plt.ylabel('Y')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def generate_mesh(n, random_pts = 0):\n",
    "    \"\"\"\n",
    "    Generated a mesh of n x and y values.\n",
    "    \"\"\"\n",
    "    if random_pts == 0:\n",
    "        x = np.linspace(0, 1, n)\n",
    "        y = np.linspace(0, 1, n)\n",
    "    if random_pts == 1:\n",
    "        x = np.random.rand(n)\n",
    "        y = np.random.rand(n)\n",
    "    return np.meshgrid(x, y)\n",
    "\n",
    "\n",
    "def frankie_function(x, y, n, sigma = 0, mu = 0):\n",
    "    \"\"\"\n",
    "    Calculates the values of the Franke function.\n",
    "    Returns these values with an element of noise if specified.\n",
    "    \"\"\"\n",
    "    term1 = 0.75*np.exp(-(0.25*(9*x-2)**2) - 0.25*((9*y-2)**2))\n",
    "    term2 = 0.75*np.exp(-((9*x+1)**2)/49.0 - 0.1*(9*y+1))\n",
    "    term3 = 0.5*np.exp(-(9*x-7)**2/4.0 - 0.25*((9*y-3)**2))\n",
    "    term4 = -0.2*np.exp(-(9*x-4)**2 - (9*y-7)**2)\n",
    "    return term1 + term2 + term3 + term4 + np.random.normal(mu, sigma, n)\n",
    "\n",
    "\n",
    "def create_design_matrix(x, y, deg):\n",
    "    \"\"\"\n",
    "    Creates a design matrix with columns:\n",
    "    [1  x  y  x^2  y^2  xy  x^3  y^3  x^2y ...]\n",
    "    \"\"\"\n",
    "    if len(x.shape) > 1:\n",
    "        x = np.ravel(x)\n",
    "        y = np.ravel(y)\n",
    "\n",
    "    N = len(x)\n",
    "    p = int((deg + 1)*(deg + 2)/2)\n",
    "    X = np.ones((N,p))\n",
    "\n",
    "    for i in range(1, deg + 1):\n",
    "        q = int((i)*(i+1)/2)\n",
    "        for k in range(i+1):\n",
    "            X[:,q+k] = x**(i-k) * y**k\n",
    "\n",
    "    return X\n",
    "\n",
    "\n",
    "\n",
    "def plot_model(x, y, z, model, deg):\n",
    "    \"\"\"\n",
    "    Function for plotting a height map of the predicted output values of a model,\n",
    "    and the raw terrain data.\n",
    "    Inputs:\n",
    "    -model, instanciated model\n",
    "    -deg, degree of the model\n",
    "    \"\"\"\n",
    "\n",
    "    #perform regression on the data and predict\n",
    "    X = create_design_matrix(x, y, deg)\n",
    "    z_flat = np.ravel(z)\n",
    "    model.fit(X, z_flat)\n",
    "    z_pred = model.predict(X).reshape(len(x), len(y))\n",
    "\n",
    "    #plotting\n",
    "    plt.rcParams.update({'font.size': 14})\n",
    "    fig = plt.figure()\n",
    "    ax1 = fig.add_subplot(1,2,1, projection='3d', gridspec_kw = {'wspace':0, 'hspace':0})\n",
    "    ax2 = fig.add_subplot(1, 2, 2, projection='3d', gridspec_kw = {'wspace':0, 'hspace':0})\n",
    "    surf1 = ax1.plot_surface(x, y, z_pred, cmap=cm.terrain, alpha=0.9)\n",
    "    surf2 = ax2.plot_surface(x, y, z, cmap=cm.terrain, alpha=0.9)\n",
    "    ax1.set_zlim(0.75, 1.75)\n",
    "    ax2.set_zlim(0.75, 1.75)\n",
    "    ax1.set_xlabel('x')\n",
    "    ax1.set_ylabel('y')\n",
    "    ax1.set_zlabel('Height [km]')\n",
    "    ax2.set_xlabel('x')\n",
    "    ax2.set_ylabel('y')\n",
    "    ax2.set_zlabel('Height [km]')\n",
    "    ax1.title.set_text('Modelled terrain')\n",
    "    ax2.title.set_text('Actual terrain')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import seaborn as sns\n",
    "from matplotlib.patches import Rectangle\n",
    "import time\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def model_degree_analysis(x, y, z, model_name, min_deg=1, max_deg=10, n_bootstraps = 100, alpha = 0, ID = '000'):\n",
    "    \"\"\"\n",
    "    Function for analyzing the performance of a model for different model complexities.\n",
    "    Performs bootstrap resampling for each configuration.\n",
    "    Plots the MSE of the training error and test error for each configuration,\n",
    "    and the bias^2 - variance decomposition of the testing error.\n",
    "    The error scores for each configuration is also saved to a .csv file.\n",
    "    Inputs:\n",
    "    -x, y values, dimensions (n, n)\n",
    "    -z values, dimension (n^2, 1)\n",
    "    -model_name, name of the model: 'ols', 'ridge', 'lasso'\n",
    "    -min_deg, max_deg - degrees to analyze\n",
    "    -n_bootstraps - number of resamples in bootstrap\n",
    "    -alpha - hyperparameter in 'ridge' and 'lasso'\n",
    "    -ID - figure IDs\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    #setup directories\n",
    "    dat_filename = 'results/' + 'error_scores_deg_analysis_' + model_name\n",
    "    fig_filename = 'figures/' + 'deg_analysis_' + model_name\n",
    "    error_scores = pd.DataFrame(columns=['degree', 'mse', 'bias', 'variance', 'r2', 'mse_train'])\n",
    "\n",
    "    #initialize regression model and arrays for saving error values\n",
    "    model = RegressionMethods(model_name, alpha=alpha)\n",
    "    degrees = np.linspace(min_deg, max_deg, max_deg - min_deg + 1)\n",
    "    nDegs = len(degrees)\n",
    "    mse = np.zeros(nDegs)\n",
    "    bias = np.zeros(nDegs)\n",
    "    variance = np.zeros(nDegs)\n",
    "    r2 = np.zeros(nDegs)\n",
    "    mse_train = np.zeros(nDegs)\n",
    "\n",
    "\n",
    "    min_mse = 1e100\n",
    "    min_r2 = 0\n",
    "    min_deg = 0\n",
    "    i = 0\n",
    "\n",
    "    #loop through the specified degrees to be analyzed\n",
    "    for deg in degrees:\n",
    "        X = create_design_matrix(x, y, int(deg))\n",
    "        resample = Resampling(X, z)\n",
    "\n",
    "        #perform bootstrap resampling and save error values\n",
    "        mse[i], bias[i], variance[i], mse_train[i], r2[i] = resample.bootstrap(model, n_bootstraps)\n",
    "\n",
    "        #save to pandas dataframe\n",
    "        error_scores = error_scores.append({'degree': degrees[i],\n",
    "                                            'mse': mse[i],\n",
    "                                            'bias': bias[i],\n",
    "                                            'variance': variance[i],\n",
    "                                            'r2': r2[i],\n",
    "                                            'mse_train': mse_train[i]}, ignore_index=True)\n",
    "\n",
    "        #check if this configuration gives smallest error\n",
    "        if mse[i] < min_mse:\n",
    "            min_mse = mse[i]\n",
    "            min_r2 = r2[i]\n",
    "            min_deg = deg\n",
    "\n",
    "\n",
    "        i += 1\n",
    "    #end for\n",
    "\n",
    "\n",
    "    #plot error of test set and training set\n",
    "    plt.plot(degrees, mse, label='test set')\n",
    "    plt.plot(degrees, mse_train, label='training set')\n",
    "    plt.legend()\n",
    "    plt.xlabel('Model complexity [degree]')\n",
    "    plt.ylabel('Mean Squared Error')\n",
    "    plt.savefig(fig_filename + '_test_train_' + ID + '.pdf')\n",
    "    plt.show()\n",
    "\n",
    "    #plot bias^2 variance decomposition of the test error\n",
    "    plt.plot(degrees, mse, label='mse')\n",
    "    plt.plot(degrees, bias,'--', label='bias')\n",
    "    plt.plot(degrees, variance, label='variance')\n",
    "    plt.xlabel('Model complexity [degree]')\n",
    "    plt.ylabel('Mean Squared Error')\n",
    "    plt.legend()\n",
    "    plt.savefig(fig_filename + '_bias_variance_' + ID + '.pdf')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    #save error scores to file\n",
    "    error_scores.to_csv(dat_filename + '.csv')\n",
    "    print('min mse:', min_mse)\n",
    "    print('r2:', min_r2)\n",
    "    print('deg:', min_deg)\n",
    "\n",
    "\n",
    "\n",
    "def ridge_lasso_complexity_analysis(x, y, z, model_name, min_deg=1, max_deg=10, n_lambdas=13, min_lamb=-10, max_lamb=2, ID = '000'):\n",
    "    \"\"\"\n",
    "    Function for analyzing ridge or lasso model performance for\n",
    "    different values lambda and model complexity.\n",
    "    Performs bootstrap resampling for each configuration and plots\n",
    "    a heat map of the error for each configuration. Error scores are\n",
    "    also saved to a .csv file.\n",
    "    Inputs:\n",
    "    -x, y values, dimensions (n, n)\n",
    "    -z values, dimension (n^2, 1)\n",
    "    -model_name, name of the model: 'ridge', 'lasso'\n",
    "    -min_deg, max_deg - degrees to analyze\n",
    "    -min_lamb, max_lamb, n_lambdas - values of log_10(lambda) to analyze, and how many\n",
    "    -ID - figure IDs\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    #initialize model and arrays for parameters lambda and complexity\n",
    "    model = RegressionMethods(model_name)\n",
    "    lambdas = np.linspace(min_lamb, max_lamb, n_lambdas)\n",
    "    degrees = np.linspace(min_deg, max_deg, max_deg - min_deg + 1)\n",
    "\n",
    "    #setup directories\n",
    "    dat_filename = 'results/' + 'error_scores_' + model_name\n",
    "    fig_filename = 'figures/' + 'min_mse_meatmap_' + model_name\n",
    "    error_scores = pd.DataFrame(columns=['degree', 'log lambda', 'mse', 'bias', 'variance', 'r2', 'mse_train'])\n",
    "\n",
    "\n",
    "    min_mse = 1e100\n",
    "    min_lambda = 0\n",
    "    min_degree = 0\n",
    "    min_r2 = 0\n",
    "\n",
    "\n",
    "    i = 0\n",
    "    #loop through specified degrees\n",
    "    for deg in degrees:\n",
    "        j = 0\n",
    "        X = create_design_matrix(x, y, int(deg))\n",
    "        resample = Resampling(X, z)\n",
    "        #loop through specified lambdas\n",
    "        for lamb in tqdm(lambdas):\n",
    "            model.set_alpha(10**lamb)\n",
    "\n",
    "            #perform resampling\n",
    "            mse, bias, variance, mse_train, r2 = resample.bootstrap(model, n_bootstraps=10)\n",
    "\n",
    "            #save error scores in pandas dataframe\n",
    "            error_scores = error_scores.append({'degree': deg,\n",
    "                                                'log lambda': lamb,\n",
    "                                                'mse': mse,\n",
    "                                                'bias': bias,\n",
    "                                                'variance': variance,\n",
    "                                                'r2': r2,\n",
    "                                                'mse_train': mse_train}, ignore_index=True)\n",
    "\n",
    "            #check if current configuration gives minimal error\n",
    "            if mse < min_mse:\n",
    "                min_mse = mse\n",
    "                min_lambda = lamb\n",
    "                min_degree = deg\n",
    "                min_r2 = r2\n",
    "\n",
    "            j+=1\n",
    "        #end for lambdas\n",
    "        i+=1\n",
    "    #end for degrees\n",
    "\n",
    "    print('min mse:', min_mse)\n",
    "    print('min r2:', min_r2)\n",
    "    print('degree:', min_degree)\n",
    "    print('lambda:', min_lambda)\n",
    "\n",
    "\n",
    "    #save scores to file\n",
    "    error_scores.to_csv(dat_filename + '.csv')\n",
    "\n",
    "\n",
    "\n",
    "    #plot heat map of error scores of each configuration\n",
    "    mse_table = pd.pivot_table(error_scores, values='mse', index=['degree'], columns='log lambda')\n",
    "    idx_i = np.where(mse_table == min_mse)[0]\n",
    "    idx_j = np.where(mse_table == min_mse)[1]\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = sns.heatmap(mse_table, annot=True, fmt='.2g', cbar=True, linewidths=1, linecolor='white',\n",
    "                            cbar_kws={'label': 'Mean Squared Error'})\n",
    "    ax.add_patch(Rectangle((idx_j, idx_i), 1, 1, fill=False, edgecolor='red', lw=3))\n",
    "\n",
    "    ax.set_xlabel(r\"$\\log_{10}(\\lambda)$\")\n",
    "    ax.set_ylabel(\"Complexity\")\n",
    "    ax.set_ylim(len(degrees), 0)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def confidence_intervals(x, y, z_flat, model, degree, alpha = 0, noise = 0):\n",
    "    \"\"\"\n",
    "    Function for finding the estimated confidence intervals of a given models beta-parameters,\n",
    "    and makes a plot of the parameters with confidence intervals corresponing to\n",
    "    a 95% confidence interval.\n",
    "    \"\"\"\n",
    "    X = create_design_matrix(x, y, degree)\n",
    "    resample = Resampling(X, z_flat)\n",
    "    betas, variance = resample.bootstrap(model, get_beta_var=True)\n",
    "\n",
    "    CI = 1.96*np.sqrt(variance)\n",
    "\n",
    "\n",
    "    #plotting\n",
    "    plt.xticks(np.arange(0, len(betas), step=1))\n",
    "    plt.errorbar(range(len(betas)), betas, CI, fmt=\"b.\", capsize=3, label=r'$\\beta_j \\pm 1.96 \\sigma$')\n",
    "    plt.legend()\n",
    "    plt.xlabel(r'index $j$')\n",
    "    plt.ylabel(r'$\\beta_j$')\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def confidence_interval_ols(X, z):\n",
    "    \"\"\"\n",
    "    Function for finding the confidence intervals of the OLS beta-parameters.\n",
    "    Uses the analytical expression of the variance. Makes a plot of the beta-parameters with\n",
    "    error bars corresponing to 95% confidence interval.\n",
    "    \"\"\"\n",
    "\n",
    "    model = RegressionMethods('ols')\n",
    "    model.fit(X, z)\n",
    "    betas = model.beta\n",
    "    cov = np.var(z)*np.linalg.pinv(X.T.dot(X))\n",
    "    std_betas = np.sqrt(np.diag(cov))\n",
    "    CI = 1.96*std_betas\n",
    "\n",
    "\n",
    "    #plot results\n",
    "    plt.errorbar(range(len(betas)), betas, CI, fmt=\"b.\", capsize=3, label=r'$\\beta_j \\pm 1.96 \\sigma$')\n",
    "    plt.ticklabel_format(style='sci', axis='y', scilimits=(0,0))\n",
    "    plt.legend()\n",
    "    plt.xlabel(r'index $j$')\n",
    "    plt.ylabel(r'$\\beta_j$')\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#performing the analysis of the regression methods\n",
    "np.random.seed(100)\n",
    "n = 20\n",
    "deg = 5\n",
    "sigma = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frankie data\n",
    "x, y = generate_mesh(n)\n",
    "z = frankie_function(x, y, n, sigma)\n",
    "z_flat = np.ravel(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "No such file: 'C:\\Users\\bod\\OneDrive - Universitetet i Oslo\\DL and ML\\Project 1\\data\\norway1.tif'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-85739521b08a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# terrain data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mterrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_terrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'norway1.tif'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mz_flat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mterrain_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerate_mesh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-65059bb19ef6>\u001b[0m in \u001b[0;36mload_terrain\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m     17\u001b[0m     \"\"\"\n\u001b[0;32m     18\u001b[0m     \u001b[0mslice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[0mterrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data/'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m     \u001b[0mdims\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mterrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdims\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\imageio\\core\\functions.py\u001b[0m in \u001b[0;36mimread\u001b[1;34m(uri, format, **kwargs)\u001b[0m\n\u001b[0;32m    262\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m     \u001b[1;31m# Get reader and read first\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 264\u001b[1;33m     \u001b[0mreader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muri\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"i\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    265\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mreader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mreader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\imageio\\core\\functions.py\u001b[0m in \u001b[0;36mget_reader\u001b[1;34m(uri, format, mode, **kwargs)\u001b[0m\n\u001b[0;32m    171\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m     \u001b[1;31m# Create request object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 173\u001b[1;33m     \u001b[0mrequest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muri\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"r\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    174\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m     \u001b[1;31m# Get format\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\imageio\\core\\request.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, uri, mode, **kwargs)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m         \u001b[1;31m# Parse what was given\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 126\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parse_uri\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muri\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    127\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m         \u001b[1;31m# Set extension\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\imageio\\core\\request.py\u001b[0m in \u001b[0;36m_parse_uri\u001b[1;34m(self, uri)\u001b[0m\n\u001b[0;32m    276\u001b[0m                 \u001b[1;31m# Reading: check that the file exists (but is allowed a dir)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    277\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 278\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"No such file: '%s'\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    279\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    280\u001b[0m                 \u001b[1;31m# Writing: check that the directory to write to does exist\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: No such file: 'C:\\Users\\bod\\OneDrive - Universitetet i Oslo\\DL and ML\\Project 1\\data\\norway1.tif'"
     ]
    }
   ],
   "source": [
    "# terrain data\n",
    "terrain_data, n = load_terrain('norway1.tif')\n",
    "z_flat = np.ravel(terrain_data)\n",
    "x, y = generate_mesh(n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnitTests():\n",
    "    \"\"\"\n",
    "    Tests the OLS and Ridge implementations in the RegressionMethods class, by\n",
    "    comparing its results with sklearns equivalent methods.\n",
    "    A test case is initialized automatically in the __init__ function.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.n = 100\n",
    "        np.random.seed(10)\n",
    "        degree = 5\n",
    "        sigma = 0.3\n",
    "        x, y = generate_mesh(self.n)\n",
    "        z = frankie_function(x, y, self.n, sigma)\n",
    "        self.z_flat = np.ravel(z)\n",
    "        self.X = create_design_matrix(x, y, degree)\n",
    "        self.tol = 1e-15\n",
    "\n",
    "    def test_ols(self):\n",
    "\n",
    "        #perform ols on the data with sklean\n",
    "        clf = skl.LinearRegression().fit(self.X, self.z_flat)\n",
    "        z_pred_skl = clf.predict(self.X)\n",
    "\n",
    "\n",
    "        #perform ols with our implementation\n",
    "        model = RegressionMethods('ols')\n",
    "        model.fit(self.X, self.z_flat)\n",
    "        z_pred_model = model.predict(self.X)\n",
    "\n",
    "        #assert difference in our implementation and sklearns\n",
    "        diff = mean_squared_error(z_pred_skl, z_pred_model)\n",
    "        print(\"Test OLS:\")\n",
    "        print(\"Max diff: \", diff)\n",
    "        assert diff < self.tol\n",
    "\n",
    "\n",
    "    def test_ridge(self):\n",
    "\n",
    "        #perform ridge on the data with sklearn\n",
    "        alpha = 0.1\n",
    "        clf = skl.Ridge(alpha = alpha, fit_intercept=False).fit(self.X, self.z_flat)\n",
    "        z_pred_skl = clf.predict(self.X)\n",
    "\n",
    "        #perform ridge on the data with our implementation\n",
    "        model = RegressionMethods(method = 'ridge', alpha = alpha)\n",
    "        model.fit(self.X, self.z_flat)\n",
    "        z_pred_model = model.predict(self.X)\n",
    "\n",
    "        #assert difference\n",
    "        diff = mean_squared_error(z_pred_skl, z_pred_model)\n",
    "        print(\"Test Ridge:\")\n",
    "        print(\"Max diff: \", diff)\n",
    "        assert diff < self.tol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
